# ExcelBench

A comprehensive benchmark suite comparing Excel libraries' **feature parity** across Python and Rust ecosystems.

## Why ExcelBench?

Most Excel library comparisons focus on speed. But the real question developers have is: **"Can this library handle my complex spreadsheet?"**

ExcelBench measures **fidelity** - how accurately each library can read and write Excel features compared to native Excel. We test the nuances: border thickness, conditional formatting rules, pivot table structures, formula preservation, and 20+ other feature categories.

## Scoring System

Each feature is scored on a 0-3 scale for both **Read** and **Write** capabilities:

| Score | Meaning |
|-------|---------|
| ðŸ”´ 0 | Unsupported - errors, corruption, or complete data loss |
| ðŸŸ  1 | Minimal - basic recognition but significant limitations |
| ðŸŸ¡ 2 | Functional - works for common cases, some edge case failures |
| ðŸŸ¢ 3 | Complete - full fidelity, indistinguishable from Excel |

## Libraries Tested

**Current (implemented):**
- openpyxl (read/write)
- xlsxwriter (write-only)
- python-calamine (read-only, Rust-backed)
- pylightxl (read/write, zero-dependency)

**Planned:**
- pyexcel, xlrd
- Rust: rust_xlsxwriter, umya-spreadsheet

## Features Tested

### Tier 1 - Essential
Cell values, formulas, text formatting, background colors, number formats, alignment, borders, dimensions, multiple sheets

### Tier 2 - Standard (Implemented)
Merged cells, conditional formatting, data validation, hyperlinks, images, pivot tables, comments, freeze panes

### Tier 3 - Advanced
Charts, named ranges, complex conditional formatting, tables, print settings, protection

## Quick Start

```bash
# Install dependencies
uv sync

# Generate canonical fixtures (requires Excel installed)
uv run excelbench generate --output fixtures/excel

# Run benchmark
uv run excelbench benchmark --tests fixtures/excel --output results

# View results
cat results/README.md
```

## Results

See [results/README.md](results/README.md) for the latest benchmark results.

## Methodology

Our methodology ensures reproducible, objective scoring:

1. **Test files generated by real Excel** via xlwings - guaranteed correct reference files
2. **Detailed scoring rubrics** define exactly what qualifies for each score level
3. **Independent read/write scores** because capabilities often differ
4. **Edge case coverage** informed by real-world pain points from GitHub issues

Full methodology: [METHODOLOGY.md](METHODOLOGY.md)

## Project Status

ðŸš§ **In Development** - Tier 1 completion underway

## License

MIT
